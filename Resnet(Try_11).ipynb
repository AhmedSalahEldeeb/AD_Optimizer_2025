{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Tytk0tRvBde"
      },
      "outputs": [],
      "source": [
        "#! kaggle datasets download uraninjo/augmented-alzheimer-mri-datasetm\n",
        "\n",
        "###https://www.kaggle.com/datasets/uraninjo/augmented-alzheimer-mri-dataset-v2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gJayACEbvJI"
      },
      "source": [
        "**In this NoteBook**, a convolutional neural network (CNN)-based Alzheimer MRI images classification algorithm is developed using **ResNet152V2** architecture, to detect **\"Mild Demented\"**, **\"Moderate Demented\"**, **\"Non Demented\"** and **\"Very Mild Demented\"** in patient's MRI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zb1f6lLqcAIH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import matplotlib.pyplot as plt\n",
        "#from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import applications\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing.image import  ImageDataGenerator\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rb4qKqZMpagI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2MseXgCcLg_"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "from helper_functions import plot_loss_curves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc2cMThAcWwn"
      },
      "source": [
        "#  Uploading the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0fR2-qNcdM3"
      },
      "outputs": [],
      "source": [
        "########### splitting data ############\n",
        "%pip install split-folders\n",
        "import splitfolders\n",
        "splitfolders.ratio('..///content/drive/MyDrive/ResnetDataset/AugmentedDataSet', output=\"input\", seed=1345, ratio=(0.7,0.3,0))\n",
        "\n",
        "SAMPLE_PER_CATEGORY = 200\n",
        "SEED = 42\n",
        "WIDTH = 128\n",
        "HEIGHT = 128\n",
        "DEPTH = 3\n",
        "INPUT_SHAPE = (WIDTH, HEIGHT, DEPTH)\n",
        "data_dir = '..///content/input'\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "test_dir = os.path.join(data_dir, 'val')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1p88-RPmR2h"
      },
      "source": [
        "**Mathematical model for Hyper param tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ldy0NYdcw3O"
      },
      "source": [
        "# Defining Categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4tzRs3rDgfj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFKCfvtPc0KQ"
      },
      "outputs": [],
      "source": [
        "CATEGORIES = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n",
        "NUM_CATEGORIES = len(CATEGORIES)\n",
        "NUM_CATEGORIES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKLMnFegc8Gj"
      },
      "source": [
        "### Calculating the number of images in each category in training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dupXKKcc5NF"
      },
      "outputs": [],
      "source": [
        "for category in CATEGORIES:\n",
        "  print('{} {} images'.format(category, len(os.listdir(os.path.join(train_dir, category)))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIR0yA_GeqlR"
      },
      "source": [
        "# Creating Train and Validation DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8y1lW8KetAe"
      },
      "outputs": [],
      "source": [
        "train = []\n",
        "for category_id, category in enumerate(CATEGORIES):\n",
        "    for file in os.listdir(os.path.join(train_dir, category)):\n",
        "        train.append(['train/{}/{}'.format(category, file), category_id, category])\n",
        "train = pd.DataFrame(train, columns=['file', 'category_id', 'category'])\n",
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkYL8g_6ezH5"
      },
      "outputs": [],
      "source": [
        "train = train.sample(frac=1)\n",
        "X = train.drop(columns = 'category_id')\n",
        "y = train['category_id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onyTceXqe31D"
      },
      "outputs": [],
      "source": [
        "x_train, x_valid, y_train, y_valid = train_test_split(X, y, test_size=0.30, random_state=4) ###### train size from 0.2 to 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0M0MlsLe_7R"
      },
      "outputs": [],
      "source": [
        "train = pd.concat([x_train, y_train], axis=1)\n",
        "validation = pd.concat([x_valid, y_valid], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLX6w0_7fEGr"
      },
      "outputs": [],
      "source": [
        "train = train.reset_index()\n",
        "train = train.drop(columns = 'index')\n",
        "validation = validation.reset_index()\n",
        "validation = validation.drop(columns = 'index')\n",
        "print(train.shape)\n",
        "print(validation.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNMLYtgUfHq-"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBNTIumjfNIX"
      },
      "outputs": [],
      "source": [
        "validation.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2x6knaNfUsQ"
      },
      "source": [
        "# Creating Test DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvjlC8StfQ78"
      },
      "outputs": [],
      "source": [
        "test = []\n",
        "for category_id, category in enumerate(CATEGORIES):\n",
        "    for file in os.listdir(os.path.join(test_dir, category)):\n",
        "        test.append(['val/{}/{}'.format(category, file), category_id, category])\n",
        "test = pd.DataFrame(test, columns=['file', 'category_id', 'category'])\n",
        "test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPFbrrWAffo9"
      },
      "source": [
        "# Demonstrating Example Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0yiUoDafcNT"
      },
      "outputs": [],
      "source": [
        "def read_img(filepath, size):\n",
        "    img = image.load_img(os.path.join(data_dir, filepath), target_size=size)\n",
        "    img = image.img_to_array(img)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqQknXDYfk9s"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(1, figsize=(NUM_CATEGORIES, NUM_CATEGORIES))\n",
        "grid = ImageGrid(fig, 111, nrows_ncols=(NUM_CATEGORIES, NUM_CATEGORIES), axes_pad=0.05)\n",
        "\n",
        "i=0\n",
        "for category_id, category in enumerate(CATEGORIES):\n",
        "    for filepath in train[train['category'] == category]['file'].values[:NUM_CATEGORIES]:\n",
        "        ax = grid[i]\n",
        "        img = read_img(filepath, (WIDTH, HEIGHT))\n",
        "        ax.imshow(img / 255.)\n",
        "        ax.axis('off')\n",
        "        if i % NUM_CATEGORIES == NUM_CATEGORIES - 1:\n",
        "            ax.text(250, 112, filepath.split('/')[1], verticalalignment='center')\n",
        "        i+=1\n",
        "\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yhg_ra9sfr2m"
      },
      "source": [
        "# Keras ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_noA_YEfnsz"
      },
      "outputs": [],
      "source": [
        "datagen_train = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = datagen_train.flow_from_dataframe(dataframe=train,\n",
        "                                                  directory=\"..///content/input\",\n",
        "                                                  x_col=\"file\",\n",
        "                                                  y_col=\"category\",\n",
        "                                                  batch_size=2,\n",
        "                                                  seed=SEED,\n",
        "                                                  shuffle=True,\n",
        "                                                  class_mode=\"categorical\",\n",
        "                                                  target_size=(HEIGHT, WIDTH));\n",
        "\n",
        "validation_generator = datagen_train.flow_from_dataframe(dataframe=validation,\n",
        "                                                  directory=\"..///content/input\",\n",
        "                                                  x_col=\"file\",\n",
        "                                                  y_col=\"category\",\n",
        "                                                  batch_size=2,\n",
        "                                                  seed=SEED,\n",
        "                                                  shuffle=True,\n",
        "                                                  class_mode=\"categorical\",\n",
        "                                                  target_size=(HEIGHT, WIDTH));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7-99q9dfyX5"
      },
      "outputs": [],
      "source": [
        "datagen_test = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen_test.flow_from_dataframe(dataframe=test,\n",
        "                                                  directory=\"..///content/input\",\n",
        "                                                  x_col=\"file\",\n",
        "                                                  y_col=\"category\",\n",
        "                                                  batch_size=2,\n",
        "                                                  seed=SEED,\n",
        "                                                  shuffle=False,\n",
        "                                                  class_mode=\"categorical\",\n",
        "                                                  target_size=(HEIGHT, WIDTH));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IBW53shf5e8"
      },
      "source": [
        "## Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiRsiKL_f1yv"
      },
      "outputs": [],
      "source": [
        "#early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZGt2kI9FmaI"
      },
      "source": [
        "###Creating CallBacks   ===> 8-8-2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5N0fYTa8Fqpt"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter Tuning ===>   8-8-2023\n",
        "callbacks = [\n",
        "   # ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True),\n",
        "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBX27Ko7gF0L"
      },
      "source": [
        "# Creating Model based on ResNet152V2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRgIUGL4gCLx"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "\n",
        "    resnet_model = tf.keras.applications.resnet_v2.ResNet152V2(\n",
        "        weights='imagenet',\n",
        "        include_top = False,\n",
        "        #input_shape = (224, 224, 3)\n",
        "        input_shape = (128, 128, 3)\n",
        "\n",
        "    )\n",
        "\n",
        "    for layers in resnet_model.layers[:100]:\n",
        "        layers.trainable = False\n",
        "    for layers in resnet_model.layers[100:]:\n",
        "        layers.trainable = True\n",
        "\n",
        "    x = resnet_model.output\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    x = tf.keras.layers.Dropout(0.50)(x)\n",
        "    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dropout(0.50)(x)\n",
        "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dropout(0.50)(x)\n",
        "    # output layer\n",
        "    predictions = tf.keras.layers.Dense(4, activation='softmax')(x)\n",
        "\n",
        "    res_model = tf.keras.Model(inputs=resnet_model.input, outputs=predictions)\n",
        "\n",
        "    # Compiling the model\n",
        "    #optimizer = tf.keras.optimizers.Adam()\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "    #optimizer = tf.keras.optimizers.RMSprop()\n",
        "    #res_model.compile(loss='categorical_crossentropy', optimizer='ٌadam', metrics=['accuracy'])\n",
        "    res_model.compile(loss='categorical_crossentropy', optimizer= optimizer, metrics=['accuracy'])\n",
        "    return res_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eda4UH9CgLSV"
      },
      "outputs": [],
      "source": [
        "res_model = create_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7onTHCvgWWj"
      },
      "outputs": [],
      "source": [
        "res_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdXohWFuLGSH"
      },
      "outputs": [],
      "source": [
        "# Model Architecture Visualization\n",
        "#tf.keras.utils.plot_model(res_model, to_file='resnet152v2.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgh3KRJ9gfDW"
      },
      "source": [
        "# Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8Ni_uCCgZ2a"
      },
      "outputs": [],
      "source": [
        "history = res_model.fit(train_generator,\n",
        "                    #steps_per_epoch=len(train_generator),\n",
        "                    epochs=160,\n",
        "                    validation_data=validation_generator,\n",
        "                    #validation_steps=len(validation_generator),\n",
        "                    callbacks=callbacks,\n",
        "                    batch_size=2,\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu8N1kqMgpuJ"
      },
      "source": [
        "# Plotting the history of model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxk9c367gl-S"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkE3-uLFg2_S"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiHBLvQYgxQh"
      },
      "outputs": [],
      "source": [
        "valid_loss, valid_accuracy = res_model.evaluate(validation_generator)\n",
        "\n",
        "print(f'\\nTrain loss: {valid_loss:.2f}')\n",
        "print(f'Train Accuracy: {valid_accuracy*100:.2f} %')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGjbW1YahATH"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = res_model.evaluate(test_generator)\n",
        "\n",
        "print(f'\\nTest loss: {loss:.2f} ')\n",
        "print(f'Test Accuracy: {accuracy*100:.2f} %')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SNHpYFArwkA"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = res_model.evaluate(test_generator)\n",
        "\n",
        "print(f'\\nTest loss: {loss:.2f} ')\n",
        "print(f'Test Accuracy: {accuracy*100:.2f} %')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3foHF0SQhBEs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX7gKbznr6X1"
      },
      "outputs": [],
      "source": [
        "y_predict = res_model.predict(test_generator)\n",
        "prediction = np.argmax(y_predict,axis=1)\n",
        "labels = (train_generator.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "prediction = [labels[k] for k in prediction]\n",
        "\n",
        "y_test = list(test.category)\n",
        "\n",
        "report = classification_report(y_test, prediction, output_dict=True)\n",
        "df = pd.DataFrame(report).transpose()\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pdf1lAnC6YgN"
      },
      "source": [
        "####Create the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sc2Rnkq26fM6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "# Set the number of classes for your task\n",
        "num_classes = 4\n",
        "\n",
        "# Generate predictions on the test dataset\n",
        "y_true = test_generator.classes\n",
        "y_pred = res_model.predict(test_generator)\n",
        "\n",
        "# Get predicted classes\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "'''\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.set(font_scale=1.2)\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=plt.cm.Blues, cbar=False,\n",
        "            annot_kws={\"size\": 15}, linewidths=0.5, square=True,\n",
        "            xticklabels=['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented'], yticklabels=['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented'])\n",
        "'''\n",
        "# Plot confusion matrix\n",
        "plt.imshow(conf_matrix, cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.colorbar()\n",
        "plt.xlabel(\"Predicted labels\")\n",
        "plt.ylabel(\"True labels\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pFHwszGxjyR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOZHsns-sLJq"
      },
      "outputs": [],
      "source": [
        "# Evaluate the Model on Test Data   ======>9-8-2023\n",
        "test_loss, test_accuracy = res_model.evaluate(test_generator, steps=len(test_generator))\n",
        "print(\"Test Loss:\", test_loss)\n",
        "#print(\"Test Accuracy:\", test_accuracy)\n",
        "print(f'Test Accuracy:: {test_accuracy*100:.2f} %')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_F6hZdbfVf_6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoSoCcMpsbTq"
      },
      "outputs": [],
      "source": [
        "# Evaluate the Model on Train Data   ======>9-8-2023\n",
        "valid_loss, valid_accuracy = res_model.evaluate(validation_generator)\n",
        "\n",
        "print(f'\\nTrain loss: {valid_loss:.2f}')\n",
        "print(f'Train Accuracy: {valid_accuracy*100:.2f} %')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rv1j-o5NxqmO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BWURBJnseyE"
      },
      "outputs": [],
      "source": [
        "# Metrics Visualization    =====>9-8-2023\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "'''\n",
        "# Compute and Plot ROC Curves\n",
        "y_true = test_generator.classes\n",
        "y_pred = res_model.predict(test_generator)\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(4):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "for i in range(4):\n",
        "    plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPEL81JZhD37"
      },
      "outputs": [],
      "source": [
        "res_model.save('Resnet_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgoERQOxhHG8"
      },
      "outputs": [],
      "source": [
        "!zip -r dowinloadme.zip Resnet_model.h5"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}